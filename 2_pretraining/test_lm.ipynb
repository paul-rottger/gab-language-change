{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "republican-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import pipeline, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "under-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = './test-mlm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-investigator",
   "metadata": {},
   "source": [
    "## Test Mask Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wicked-boutique",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ./test-mlm and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=TEST_PATH,\n",
    "    tokenizer=TEST_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increasing-substance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'the doctor prescribed me some medicine',\n",
       "  'score': 0.226003497838974,\n",
       "  'token': 3460,\n",
       "  'token_str': 'doctor'},\n",
       " {'sequence': 'the nurse prescribed me some medicine',\n",
       "  'score': 0.030406033620238304,\n",
       "  'token': 6821,\n",
       "  'token_str': 'nurse'},\n",
       " {'sequence': 'the doctors prescribed me some medicine',\n",
       "  'score': 0.028362751007080078,\n",
       "  'token': 7435,\n",
       "  'token_str': 'doctors'},\n",
       " {'sequence': 'the man prescribed me some medicine',\n",
       "  'score': 0.027514001354575157,\n",
       "  'token': 2158,\n",
       "  'token_str': 'man'},\n",
       " {'sequence': 'the lady prescribed me some medicine',\n",
       "  'score': 0.01853339932858944,\n",
       "  'token': 3203,\n",
       "  'token_str': 'lady'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = fill_mask(\"The [MASK] prescribed me some medicine\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-friendship",
   "metadata": {},
   "source": [
    "## Test Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coordinate-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "correct-frame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized sequence: ['[USER]', ',', 'yet', 'you', 'keep', 'reply', '##ing', 'long', 'after', 'i', 'stopped', '.', '[EMOJI]', '[URL]'] \n",
      "\n",
      "tokens in sequence: 14\n",
      "characters in sequence: 65 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method PreTrainedTokenizerBase.get_special_tokens_mask of PreTrainedTokenizerFast(name_or_path='./test-mlm', vocab_size=30522, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[USER]', '[EMOJI]', '[URL]']})>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_SENTENCE = '[USER], yet you keep replying long after I stopped. [EMOJI] [URL]'\n",
    "\n",
    "# test tokenizer\n",
    "print(f'tokenized sequence: {tokenizer.tokenize(TEST_SENTENCE)} \\n')\n",
    "print(f'tokens in sequence: {len(tokenizer.tokenize(TEST_SENTENCE))}')\n",
    "print(f'characters in sequence: {len((TEST_SENTENCE))} \\n')\n",
    "\n",
    "# print special tokens\n",
    "tokenizer.get_special_tokens_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-employee",
   "metadata": {},
   "source": [
    "## Check distribution of lengths of tokenized vectors to set max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "raising-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    20680.000000\n",
      "mean        33.637331\n",
      "std         33.723105\n",
      "min          1.000000\n",
      "25%         15.000000\n",
      "50%         25.000000\n",
      "75%         45.000000\n",
      "max        826.000000\n",
      "Name: tokenized_length, dtype: float64 \n",
      "\n",
      "cutoff 64: affects 11.7% of data\n",
      "cutoff 128: affects 0.7% of data\n",
      "cutoff 256: affects 0.3% of data\n",
      "cutoff 512: affects 0.1% of data\n"
     ]
    }
   ],
   "source": [
    "seq_length_df = pd.read_csv(\"../0_data/clean/labelled_ghc/train_random.csv\")\n",
    "\n",
    "seq_length_df['tokenized_length'] = seq_length_df.clean_text.apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "\n",
    "print(seq_length_df.tokenized_length.describe(),'\\n')\n",
    "\n",
    "n_total = seq_length_df.shape[0]\n",
    "for cutoff in [64, 128, 256, 512]:\n",
    "    n_affected = seq_length_df[seq_length_df.tokenized_length>cutoff].shape[0]\n",
    "    print('cutoff {}: affects {:.1%} of data'.format(cutoff, n_affected/n_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-cambridge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
